---
title: "Eval Quickstart"
---

### Prerequisites

Before you start, you'll need to install Tatara. If you haven't yet, you can get set up by following the instructions in the [installation guide](/setup).

## Evals with Tatara

You can create an eval by providing an evaluation function.

```python
def is_cyberpunk_check(record: Record) -> bool:
    prompt = "Check that the following text is an example of cyberpunk fiction: \n\n {}\n\n If it is cyberpunk, write <CYBERPUNK>. If it is not, write <NOT_CYBERPUNK>.".format(record['output'])
    response = openai_client.chat.completions.create(
        messages=[{"role": "user", "content": prompt}],
        model=model_name,
        temperature=temperature,
        frequency_penalty=freq_penalty,
        max_tokens=max_tokens,

    )
    ret = response.choices[0].message.content
    if "<CYBERPUNK>" in ret:
        return True
    elif "<NOT_CYBERPUNK>" in ret:
        return False
    else:
        return is_cyberpunk_check(record)

  cyberpunk_check = Eval(
        name = "is_cyberpunk_check",
        description = "Checks whether the text is cyberpunk fiction. If it is, it returns True. If it is not, it returns False. If it is unsure, it will call itself again.",
        eval_fn = is_cyberpunk_check,
    )
```

Let's walk through what's happening. First, we implement a function called `is_cyberpunk_check`, which checks whether the output of a model call -- `record['output']` contains cyberpunk content.

## Running the Eval

To run the eval over a dataset, you can use `run_evals`, which takes a list of evals and a [dataset](/concepts/datasets) name.

```python
    my_evals = [cyberpunk_check, creativity_score_eval]
    run_evals(my_evals, ds_name)
```

<Info>
  {" "}
  The dataset will need to be created before running the evals. You can do this using
  the `init_dataset` function, which you can import with `from tatara.datasets import
  init_dataset`
</Info>

## Viewing the Results

Once `run_evals` is done running, you'll be able to view the results in the [Tatara UI](https://app.tatara.ai/evaluations).

<img height="800" src="/images/eval_run_with_arrow.png" />
