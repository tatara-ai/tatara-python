---
title: "Logging Quickstart"
---

### Prerequisites

Before you start, you'll need to install Tatara. If you haven't yet, you can get set up by following the instructions in the [installation guide](/setup).

### Initializing the client

Begin by initializing the client with your project name. The project name tells Tatara which project to log to.

```python
from tatara import tatara
# By default, logs flush when:
# * 60 seconds are up
# * the max queue size is hit (1000 by default)
# Here, we set the queue size to 1 and the flush interval to 1 second
# so we can see the logs immediately.
tatara.init(project="my test project", queue_size=1, flush_interval=1)
```

### Understanding Traces and Spans

Tatara has a concept of a [trace](/concepts#traces), which is a collection of [spans](/concepts#span). A trace is a logical unit of work that can be used to group spans together.
Because all of our spans are model calls, you can think of a trace as a "chain" of model calls.

Let's walk through an example of generating a character image. This entire process will be a Trace and each model call will be a span within it.

## Generating a character image

First, we'll make our LLM call to generate a visual description of the character. Then, we'll use the visual description to generate an image of the character using a Diffusion model.

```python
from openai import OpenAI
from tatara.tatara_types import LLMParams
import requests
from tatara.tatara_types import LLMUsageMetrics

MODEL_NAME = "gpt-3.5-turbo-1106"
FREQ_PENALTY = 0.1
TEMPERATURE = 0.1
MAX_TOKENS = 200

def generate_visual_description(character_description: str, openai_client: OpenAI):
    print("Generating visual description of your character.")
    character_visual_description_prompt  = "Generate a visual description of the following character: {}".format(character_description)

    response = openai_client.chat.completions.create(
            messages=[{"role": "user", "content": character_visual_description_prompt}],
            model=MODEL_NAME,
            temperature=TEMPERATURE,
            frequency_penalty=FREQ_PENALTY,
            max_tokens=MAX_TOKENS,
    )
    ret = response.choices[0].message.content
    tatara.current_span().log_llm_success(prompt=character_description, output=ret,
                params=LLMParams(
                model=MODEL_NAME,
                temperature=TEMPERATURE,
                frequency_penalty=FREQ_PENALTY,
                max_tokens=MAX_TOKENS,
                provider="openai",
            ),
            usage_metrics=LLMUsageMetrics.from_oai_completion_usage(
                response.usage
            ))

    return ret
```

You'll notice in the above code that we are using `tatara.current_span().log_llm_success` to log the output of the LLM model call. This will log the output of the model call to Tatara, along with the parameters used to make the call and the usage metrics of the call.

Now we'll handle the Diffusion model call to generate the character image.

```python
def generate_character_image(character_visual_description: str, openai_client: OpenAI):
    print("Generating character image")
    response = openai_client.images.generate(
        model="dall-e-3",
        prompt=character_visual_description,
        size="1024x1024",
        quality="standard",
        n=1,
    )
    image_url = response.data[0].url
    img_data = bytes(requests.get(image_url).content)
    tatara.current_span().log_diffusion_success_with_image_data(img_data, "png", prompt=character_visual_description)
    return img_data
```

Let's put it all together. We'll initialize our client, and wrap our model calls in a trace and spans so that we can see the entire process in the Tatara dashboard.

```python
if __name__ == "__main__":
    tatara.init(project="test_project", flush_interval=1, queue_size=1)
    openai_client = OpenAI()


    character_description = "a cyborg with a bionic arm and a holoband."
    visual_description_event_name = "generate_visual_description"
    image_event_name = "generate_character_image"

    with tatara.start_trace(event="create_character_image"):
        with tatara.start_span(event=visual_description_event_name):
          character_visual_description = generate_visual_description(character_description, openai_client)
        with tatara.start_span(event=image_event_name, parent_event=visual_description_event_name):
            character_image = generate_character_image(character_visual_description, openai_client)
```

## Other ways to log

You can create a span by decorating a function like this where `your_event` is the name of the event you want to log.

```python
    @log_span(event='your_event')
    def decorated_function():
        # do stuff
```

## Passing tracking information

Note that you can also pass in a `user_id` and an `id_` to the `start_trace` function to associate the trace with your user and to give the trace a unique identifier that you can use to join it to other data.

## Viewing your logs

Now head over to the [Tatara dashboard](https://app.tatara.ai) to view your logs.
